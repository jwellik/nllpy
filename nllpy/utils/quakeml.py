# =============================================================================
# nllpy/utils/quakeml.py
# =============================================================================
"""
Utilities for fetching FDSN events and converting QuakeML files to NonLinLoc observation format
"""

import os
import re
from pathlib import Path
from typing import Optional, List, Dict, Any
from datetime import datetime
from obspy import read_events, Catalog, UTCDateTime
from obspy.core.event import Event
from obspy.clients.fdsn import Client


def safe_write_nlloc_obs(event: Event, output_file: str) -> bool:
    """
    Safely write an event to NLLOC_OBS format, handling events without picks.
    
    Args:
        event: ObsPy Event object
        output_file: Path to output file
        
    Returns:
        bool: True if successful, False if failed
    """
    try:
        # Try the standard ObsPy writer first
        event.write(output_file, format="NLLOC_OBS")
        return True
    except Exception as e:
        # If ObsPy writer fails, use our custom writer
        print(f"ObsPy NLLOC_OBS writer failed: {e}")
        print("Using custom NLLOC_OBS writer...")
        return create_nlloc_obs_file(event, output_file)


def create_nlloc_obs_file(event: Event, output_file: str) -> bool:
    """
    Create a proper NLLOC_OBS file from an ObsPy Event object.
    
    Args:
        event: ObsPy Event object
        output_file: Path to output file
        
    Returns:
        bool: True if successful, False if failed
    """
    try:
        with open(output_file, 'w') as f:
            # Write header
            f.write("# NLLOC_OBS file generated by nllpy\n")
            f.write("#\n")
            
            # Get event information
            origin = event.preferred_origin()
            magnitude = event.preferred_magnitude()
            
            if origin:
                time = origin.time
                lat = origin.latitude
                lon = origin.longitude
                depth = origin.depth / 1000.0 if origin.depth else 0.0  # Convert to km
                mag_val = magnitude.mag if magnitude else 0.0
                
                # Write EVENT line
                f.write(f"EVENT {time.year:04d} {time.month:02d} {time.day:02d} "
                       f"{time.hour:02d} {time.minute:02d} {time.second:06.4f} "
                       f"{lat:8.4f} {lon:9.4f} {depth:6.2f} {mag_val:5.2f}\n")
                
                # Write picks if available
                if event.picks:
                    f.write("#\n")
                    f.write("# Station Phase Time Weight\n")
                    f.write("#\n")
                    
                    for pick in event.picks:
                        if pick.waveform_id and pick.waveform_id.station_code:
                            station = pick.waveform_id.station_code
                            phase = pick.phase_hint if pick.phase_hint else 'P'
                            pick_time = pick.time
                            
                            # Calculate relative time from event origin
                            rel_time = pick_time - time
                            
                            # Default weight (can be customized)
                            weight = 1.0
                            
                            f.write(f"{station:<5s} {phase} {rel_time:8.3f} {weight:5.2f}\n")
                else:
                    f.write("#\n")
                    f.write("# No picks available for this event\n")
                    f.write("# NonLinLoc will skip this event during location\n")
            else:
                f.write("# No origin information available\n")
                f.write("# Cannot create valid NLLOC_OBS file\n")
                return False
        
        return True
        
    except Exception as e:
        print(f"Error creating NLLOC_OBS file: {e}")
        return False


def get_fdsn_events(lat: float, lon: float, maxradius_km: float, 
                   t1: datetime, t2: datetime, client_name: str = "USGS",
                   mindepth: float = -10, maxdepth: float = 100,
                   auto_assign_picks: bool = True) -> Optional[Catalog]:
    """
    Fetch earthquake events with pick data from FDSN using ObsPy.
    Gets events first, then retrieves pick information for each event separately.
    
    Parameters:
    -----------
    lat : float
        Center latitude for event search
    lon : float
        Center longitude for event search
    maxradius_km : float
        Search radius in kilometers
    t1 : datetime or UTCDateTime
        Start time for event search
    t2 : datetime or UTCDateTime  
        End time for event search
    client_name : str
        FDSN client name (default: "USGS")
    mindepth : float
        Minimum depth in km (default: -10)
    maxdepth : float
        Maximum depth in km (default: 100)
    auto_assign_picks : bool
        Whether to auto-assign phase hints to picks based on channel name (default: True)
    Returns:
    --------
    obspy.Catalog or None
        Catalog containing events with pick information, or None if error
    """
    client = Client(client_name)
    
    # Convert to UTCDateTime if needed
    if isinstance(t1, datetime):
        t1 = UTCDateTime(t1)
    if isinstance(t2, datetime):
        t2 = UTCDateTime(t2)
    
    # Convert km to degrees (approximate)
    maxradius_deg = maxradius_km / 111.0
    
    print(f"Fetching events from {client_name}...")
    print(f"Center: {lat:.4f}, {lon:.4f}")
    print(f"Radius: {maxradius_km:.1f} km ({maxradius_deg:.3f} degrees)")
    print(f"Time range: {t1} to {t2}")
    
    try:
        # First, get all events in the region
        catalog_initial = client.get_events(
            starttime=t1,
            endtime=t2,
            latitude=lat,
            longitude=lon,
            maxradius=maxradius_deg,
            mindepth=mindepth,
            maxdepth=maxdepth
        )
        
        print(f"Found {len(catalog_initial)} events")
        
        if len(catalog_initial) == 0:
            print("No events found in the specified region and time range.")
            return Catalog()
        
        # Now get pick information for each event separately
        catalog = Catalog()
        
        for i, event in enumerate(catalog_initial):
            print(f"Getting pick information for event {i+1}/{len(catalog_initial)}...")
            
            # Get the event ID from the resource_id
            if event.origins and len(event.origins) > 0:
                rid = event.origins[0].resource_id.id
                
                # Extract event ID from resource_id (e.g., 'quakeml:earthquake.usgs.gov/product/origin/uw61501708/uw/1624049054710/product.xml')
                parts = rid.split("/")
                if len(parts) >= 4:
                    eventid = parts[3]  # e.g., "uw61501708"
                    print(f"  Event ID: {eventid}")
                    
                    # Get the event with pick information using the event ID
                    try:
                        tmp_cat = client.get_events(eventid=eventid)
                        if len(tmp_cat) > 0:
                            catalog.append(tmp_cat[0])
                            print(f"  Added event with {len(tmp_cat[0].picks)} picks")
                        else:
                            print(f"  No event found for ID: {eventid}")
                            catalog.append(event)
                    except Exception as e:
                        print(f"  Error getting picks for event {eventid}: {e}")
                        # Add the original event without picks
                        catalog.append(event)
                else:
                    print(f"  Could not extract event ID from resource_id: {rid}")
                    catalog.append(event)
            else:
                print(f"  No origin information for event {i+1}")
                catalog.append(event)

        # Assign phase hints to picks
        if auto_assign_picks:
            assign_picks(catalog, verbose=False)
        
        # Summary statistics
        total_picks = 0
        events_with_picks = 0
        for event in catalog:
            pick_count = len(event.picks)
            total_picks += pick_count
            if pick_count > 0:
                events_with_picks += 1
        
        print(f"Final catalog - Events with picks: {events_with_picks}/{len(catalog)}")
        print(f"Total picks: {total_picks}")
        
        return catalog
        
    except Exception as e:
        print(f"Error fetching events: {e}")
        return None


def clean_event_id(event_id: str) -> str:
    """
    Clean event ID to create a valid filename.
    Replaces special characters with underscores.
    
    Args:
        event_id: Original event ID
        
    Returns:
        Cleaned event ID suitable for filenames
    """
    if not event_id:
        return "unknown_event"
    
    # Replace any special characters that aren't valid in filenames
    cleaned = re.sub(r'[^\w\-_.]', '_', event_id)
    
    # Remove multiple consecutive underscores
    cleaned = re.sub(r'_+', '_', cleaned)
    
    # Remove leading/trailing underscores
    cleaned = cleaned.strip('_')
    
    # Ensure it's not empty
    if not cleaned:
        return "unknown_event"
    
    return cleaned


def extract_event_id(event: Event) -> str:
    """
    Extract a unique event ID from an ObsPy Event object.
    
    Args:
        event: ObsPy Event object
        
    Returns:
        Event ID string
    """
    # Try to get ID from origin resource_id first
    if event.origins and len(event.origins) > 0:
        rid = event.origins[0].resource_id.id
        if rid:
            # Extract event ID from resource_id (e.g., 'quakeml:earthquake.usgs.gov/product/origin/uw61501708/uw/1624049054710/product.xml')
            parts = rid.split("/")
            if len(parts) >= 4:
                return parts[3]  # e.g., "uw61501708"
    
    # Try to get ID from event resource_id
    if event.resource_id:
        rid = str(event.resource_id)
        if rid:
            # Extract last part of the resource_id
            parts = rid.split("/")
            if len(parts) > 0:
                return parts[-1]
    
    # Fallback to timestamp-based ID
    if event.preferred_origin():
        origin = event.preferred_origin()
        return f"evt_{origin.time.strftime('%Y%m%d_%H%M%S')}"
    
    # Last resort
    return "unknown_event"


def convert_quakeml_to_obs_files(quakeml_file: str, output_dir: str, 
                                event_id_pattern: Optional[str] = None,
                                overwrite: bool = False) -> Dict[str, Any]:
    """
    Convert a QuakeML file containing multiple events to individual NonLinLoc .obs files.
    
    Args:
        quakeml_file: Path to input QuakeML file
        output_dir: Directory to write .obs files
        event_id_pattern: Optional pattern to extract event IDs (e.g., "{event_id}")
        overwrite: Whether to overwrite existing files
        
    Returns:
        Dictionary with conversion statistics
    """
    # Create output directory
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Read QuakeML file
    try:
        catalog = read_events(quakeml_file)
        print(f"Read {len(catalog)} events from {quakeml_file}")
        
        # Check pick information
        pick_stats = check_event_picks(catalog)
        print(f"Pick statistics:")
        print(f"  Events with picks: {pick_stats['events_with_picks']}")
        print(f"  Events without picks: {pick_stats['events_without_picks']}")
        print(f"  Total picks: {pick_stats['total_picks']}")
        print(f"  Average picks per event: {pick_stats['avg_picks_per_event']:.1f}")
        
        if pick_stats['events_without_picks'] > 0:
            print(f"Warning: {pick_stats['events_without_picks']} events have no picks and will create minimal NLLOC_OBS files")
            
    except Exception as e:
        raise ValueError(f"Error reading QuakeML file {quakeml_file}: {e}")
    
    if len(catalog) == 0:
        return {
            "input_file": quakeml_file,
            "output_dir": str(output_path),
            "total_events": 0,
            "successful_conversions": 0,
            "failed_conversions": 0,
            "total_picks": 0,
            "output_files": []
        }
    
    # Process each event
    successful = 0
    failed = 0
    total_picks = 0
    output_files = []
    
    for i, event in enumerate(catalog):
        try:
            # Extract event ID
            event_id = extract_event_id(event)
            
            # Clean event ID for filename
            clean_id = clean_event_id(event_id)
            
            # Generate output filename
            if event_id_pattern:
                # Use custom pattern
                filename = event_id_pattern.format(
                    event_id=clean_id,
                    index=i+1,
                    total=len(catalog)
                )
            else:
                # Use default pattern
                filename = f"{clean_id}.obs"
            
            output_file = output_path / filename
            
            # Check if file exists
            if output_file.exists() and not overwrite:
                print(f"Skipping event {i+1} - file exists: {filename}")
                continue
            
            # Write event to .obs file using safe writer
            if safe_write_nlloc_obs(event, str(output_file)):
                # Count picks
                pick_count = len(event.picks)
                total_picks += pick_count
                
                print(f"Event {i+1}/{len(catalog)}: {filename} ({pick_count} picks)")
                output_files.append(str(output_file))
                successful += 1
            else:
                print(f"Failed to write event {i+1} to {filename}")
                failed += 1
            
        except Exception as e:
            print(f"Error converting event {i+1}: {e}")
            failed += 1
            continue
    
    # Return statistics
    return {
        "input_file": quakeml_file,
        "output_dir": str(output_path),
        "total_events": len(catalog),
        "successful_conversions": successful,
        "failed_conversions": failed,
        "total_picks": total_picks,
        "output_files": output_files
    }


def convert_quakeml_to_obs_file(quakeml_file: str, output_file: str, 
                               event_index: int = 0) -> Dict[str, Any]:
    """
    Convert a single event from a QuakeML file to a NonLinLoc .obs file.
    
    Args:
        quakeml_file: Path to input QuakeML file
        output_file: Path to output .obs file
        event_index: Index of event to convert (default: 0, first event)
        
    Returns:
        Dictionary with conversion information
    """
    # Read QuakeML file
    try:
        catalog = read_events(quakeml_file)
    except Exception as e:
        raise ValueError(f"Error reading QuakeML file {quakeml_file}: {e}")
    
    if len(catalog) == 0:
        raise ValueError(f"No events found in {quakeml_file}")
    
    if event_index >= len(catalog):
        raise ValueError(f"Event index {event_index} out of range (0-{len(catalog)-1})")
    
    # Get the specified event
    event = catalog[event_index]
    
    # Create output directory if needed
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Write event to .obs file using safe writer
    if not safe_write_nlloc_obs(event, str(output_path)):
        raise ValueError(f"Failed to write event to {output_path}")
    
    # Extract event information
    event_id = extract_event_id(event)
    pick_count = len(event.picks)
    
    return {
        "input_file": quakeml_file,
        "output_file": str(output_path),
        "event_index": event_index,
        "event_id": event_id,
        "pick_count": pick_count,
        "total_events_in_file": len(catalog)
    }


def assign_picks(catalog: Catalog, verbose: bool = True) -> Catalog:
    """
    Assign phase hints to picks based on channel endings when phase_hint is None.
    
    Args:
        catalog: ObsPy Catalog containing events
        verbose: Whether to print detailed information about assignments
        
    Returns:
        Catalog with modified picks (same object, modified in place)
    """
    total_events = len(catalog)
    total_picks_modified = 0
    events_with_modifications = 0
    
    if verbose:
        print(f"Assigning phase hints to {total_events} events...")
    
    for i, event in enumerate(catalog):
        picks_modified = 0
        
        if verbose:
            print(f"Event {i+1}/{total_events}: {extract_event_id(event)}")
        
        # Set phase_hint based on channel ending if it's None
        for pick in event.picks:
            if pick.phase_hint is None and pick.waveform_id and pick.waveform_id.channel_code:
                if pick.waveform_id.channel_code.endswith('Z'):
                    pick.phase_hint = 'P'
                    if verbose:
                        print(f"  Set phase_hint for {pick.waveform_id.channel_code} to P")
                else:
                    pick.phase_hint = 'S'
                    if verbose:
                        print(f"  Set phase_hint for {pick.waveform_id.channel_code} to S")
                picks_modified += 1
        
        if picks_modified > 0:
            total_picks_modified += picks_modified
            events_with_modifications += 1
            if verbose:
                print(f"  Set phase_hint for {picks_modified} picks based on channel ending")
    

    if verbose:
        print(f"\nSummary: Modified {total_picks_modified} picks in {events_with_modifications} events")
    
    return catalog


def check_event_picks(catalog: Catalog) -> Dict[str, Any]:
    """
    Check pick information in a catalog of events.
    
    Args:
        catalog: ObsPy Catalog object
        
    Returns:
        Dictionary with pick statistics
    """
    total_events = len(catalog)
    events_with_picks = 0
    events_without_picks = 0
    total_picks = 0
    
    for event in catalog:
        pick_count = len(event.picks)
        total_picks += pick_count
        if pick_count > 0:
            events_with_picks += 1
        else:
            events_without_picks += 1
    
    return {
        "total_events": total_events,
        "events_with_picks": events_with_picks,
        "events_without_picks": events_without_picks,
        "total_picks": total_picks,
        "avg_picks_per_event": total_picks / total_events if total_events > 0 else 0
    }


def print_conversion_summary(stats: Dict[str, Any]) -> None:
    """
    Print a summary of the conversion results.
    
    Args:
        stats: Statistics dictionary from conversion functions
    """
    print("\n" + "="*60)
    print("QUAKEML TO NONLINLOC CONVERSION SUMMARY")
    print("="*60)
    print(f"Input file: {stats['input_file']}")
    print(f"Output directory: {stats['output_dir']}")
    print(f"Total events in file: {stats['total_events']}")
    print(f"Successful conversions: {stats['successful_conversions']}")
    print(f"Failed conversions: {stats['failed_conversions']}")
    print(f"Total picks: {stats['total_picks']}")
    
    if stats['total_events'] > 0:
        if stats['successful_conversions'] > 0:
            avg_picks = stats['total_picks'] / stats['successful_conversions']
            print(f"Average picks per event: {avg_picks:.1f}")
        else:
            print("Average picks per event: N/A (no successful conversions)")
    
    if stats['output_files']:
        print(f"\nOutput files ({len(stats['output_files'])}):")
        for filename in sorted(stats['output_files'])[:5]:  # Show first 5
            print(f"  {Path(filename).name}")
        if len(stats['output_files']) > 5:
            print(f"  ... and {len(stats['output_files'])-5} more")
    
    print("="*60) 